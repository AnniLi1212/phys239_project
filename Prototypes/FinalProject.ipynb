{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9122053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 06:19:56.143286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-21 06:19:58.067251: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/pkgs/cudnn-8.1.0.77-h90431f1_0/lib/:/opt/conda/pkgs/cudatoolkit-11.2.2-he111cf0_8/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-21 06:19:58.067470: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/pkgs/cudnn-8.1.0.77-h90431f1_0/lib/:/opt/conda/pkgs/cudatoolkit-11.2.2-he111cf0_8/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-21 06:19:58.067498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import uproot\n",
    "import utils\n",
    "import yaml\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9859743",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('definitions_image.yml') as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    definitions = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923b398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = definitions['features']\n",
    "spectators = definitions['spectators']\n",
    "labels = definitions['labels']\n",
    "\n",
    "nfeatures = definitions['nfeatures']\n",
    "nspectators = definitions['nspectators']\n",
    "nlabels = definitions['nlabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9aaf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_to_torch(X, y):\n",
    "    X_torch = torch.tensor(X.transpose(0, 3, 1, 2), dtype=torch.float32)\n",
    "    y_torch = torch.tensor(y, dtype=torch.long)\n",
    "    return X_torch, y_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2fb5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_array, y, spec_array = utils.get_features_labels('root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/train/ntuple_merged_10.root', features, spectators, labels, remove_mass_pt_window=False, entry_stop=10000)\n",
    "# make image\n",
    "X = utils.make_image(feature_array)\n",
    "# image is a 4D tensor (n_samples, n_pixels_x, n_pixels_y, n_channels)\n",
    "X_train, y_train = keras_to_torch(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a16be8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2838/2994463492.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load testing file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeature_array_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_array_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec_array_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/test/ntuple_merged_0.root'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspectators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_mass_pt_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/private/PHYS139/Untitled Folder/utils.py\u001b[0m in \u001b[0;36mget_features_labels\u001b[0;34m(file_name, features, spectators, labels, remove_mass_pt_window, entry_stop)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mroot_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muproot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mget_file_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'deepntuplizer/tree'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     feature_array = tree.arrays(features,\n\u001b[0m\u001b[1;32m     32\u001b[0m                                 \u001b[0mentry_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentry_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                 library='np')\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/uproot/behaviors/TBranch.py\u001b[0m in \u001b[0;36marrays\u001b[0;34m(self, expressions, cut, filter_name, filter_typename, filter_branch, aliases, language, entry_start, entry_stop, decompression_executor, interpretation_executor, array_cache, library, how)\u001b[0m\n\u001b[1;32m   1255\u001b[0m                         \u001b[0mranges_or_baskets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasket_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange_or_basket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m         _ranges_or_baskets_to_arrays(\n\u001b[0m\u001b[1;32m   1258\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0mranges_or_baskets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/uproot/behaviors/TBranch.py\u001b[0m in \u001b[0;36m_ranges_or_baskets_to_arrays\u001b[0;34m(hasbranches, ranges_or_baskets, branchid_interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, library, arrays, update_ranges_or_baskets)\u001b[0m\n\u001b[1;32m   3478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3479\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranchid_interpretation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3480\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnotifications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muproot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load testing file\n",
    "feature_array_test, label_array_test, spec_array_test = utils.get_features_labels('root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/test/ntuple_merged_0.root', features, spectators, labels, remove_mass_pt_window=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accd1158",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_array_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2838/751178258.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_array_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_to_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_array_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_array_test' is not defined"
     ]
    }
   ],
   "source": [
    "# make image\n",
    "X_test = utils.make_image(feature_array_test)\n",
    "X_test, y_test = keras_to_torch(X_test, label_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0ad7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check numbers in arguments\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        print(input_shape)\n",
    "        self.conv1 = nn.Conv2d(input_shape[0], 64, kernel_size=7, stride=2, padding=3) #THIS MAY NOT BE CORRECT INPUT SHAPE\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.lrn1 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)  #64, 196\n",
    "        self.lrn2 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Inception modules\n",
    "        self.inc1 = Inception_Module(64, 'inc1') #196\n",
    "        self.inc2 = Inception_Module(256, 'inc2')\n",
    "        \n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # More inception modules\n",
    "        self.inc3 = Inception_Module(256, 'inc3')  #THIS MAY NOT BE CORRECT INPUT SHAPE, recplaced 480->256\n",
    "        \n",
    "        self.pool4 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        #self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.lrn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.lrn2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Inception modules\n",
    "        x = self.inc1(x)\n",
    "        x = self.inc2(x)\n",
    "\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # More inception modules\n",
    "        x = self.inc3(x)\n",
    "\n",
    "        x = self.pool4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37b1061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_Module(nn.Module):\n",
    "    def __init__(self, in_channels, name):\n",
    "        super(Inception_Module, self).__init__()\n",
    "        \n",
    "        self.conv_a1 = nn.Conv2d(in_channels, 64, kernel_size=1)\n",
    "        self.conv_b1 = nn.Conv2d(in_channels, 96, kernel_size=1)\n",
    "        self.conv_c1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.pool_d1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.conv_b2 = nn.Conv2d(96, 128, kernel_size=3, padding=1)\n",
    "        self.conv_c2 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
    "        self.conv_d2 = nn.Conv2d(in_channels, 32, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a1 = self.conv_a1(x)\n",
    "        b1 = self.conv_b1(x)\n",
    "        c1 = self.conv_c1(x)\n",
    "        d1 = self.pool_d1(x)\n",
    "        \n",
    "        b2 = self.conv_b2(b1)\n",
    "        c2 = self.conv_c2(c1)\n",
    "        d2 = self.conv_d2(d1)\n",
    "\n",
    "        output = torch.cat((a1, b2, c2, d2), dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13104b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, test_loader, device):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "    def train(self, epochs, learning_rate):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.train_loader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                _, labels = torch.max(labels, dim=1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "            print(f'Epoch {epoch + 1}, Loss: {running_loss / (i + 1)}')\n",
    "\n",
    "    def test(self):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in self.test_loader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print('Accuracy: %d %%' % (100 * correct / total))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73d2e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39f93c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data(X_train, y_train)\n",
    "test_dataset = Data(X_train, y_train)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6746f66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "209e3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43f3e3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and trainer\n",
    "model = CNNModel(train_dataset[0][0].shape, num_classes=num_classes)\n",
    "trainer = Trainer(model, train_loader, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26c685e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.545258476620629\n",
      "Epoch 2, Loss: 5.5452124569691765\n",
      "Epoch 3, Loss: 5.545165081413424\n",
      "Epoch 4, Loss: 5.545116340222002\n",
      "Epoch 5, Loss: 5.545066486410543\n",
      "Epoch 6, Loss: 5.545014585767474\n",
      "Epoch 7, Loss: 5.544961543310256\n",
      "Epoch 8, Loss: 5.544906376170463\n",
      "Epoch 9, Loss: 5.5448499309773345\n",
      "Epoch 10, Loss: 5.544791072404304\n"
     ]
    }
   ],
   "source": [
    "# Train and test the model\n",
    "trainer.train(epochs=10, learning_rate=0.001)\n",
    "#trainer.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

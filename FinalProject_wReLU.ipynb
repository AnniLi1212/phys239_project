{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9122053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 06:55:19.320104: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-21 06:55:21.797732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/pkgs/cudnn-8.1.0.77-h90431f1_0/lib/:/opt/conda/pkgs/cudatoolkit-11.2.2-he111cf0_8/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-21 06:55:21.798065: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/pkgs/cudnn-8.1.0.77-h90431f1_0/lib/:/opt/conda/pkgs/cudatoolkit-11.2.2-he111cf0_8/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-21 06:55:21.798086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import uproot\n",
    "import utils\n",
    "import yaml\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9859743",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('definitions_image.yml') as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    definitions = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923b398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = definitions['features']\n",
    "spectators = definitions['spectators']\n",
    "labels = definitions['labels']\n",
    "\n",
    "nfeatures = definitions['nfeatures']\n",
    "nspectators = definitions['nspectators']\n",
    "nlabels = definitions['nlabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9aaf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_to_torch(X, y):\n",
    "    X_torch = torch.tensor(X.transpose(0, 3, 1, 2), dtype=torch.float32)\n",
    "    y_torch = torch.tensor(y, dtype=torch.long)\n",
    "    return X_torch, y_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2fb5ba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_array, y, spec_array = utils.get_features_labels('root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/train/ntuple_merged_10.root', features, spectators, labels, remove_mass_pt_window=False, entry_stop=500)\n",
    "# make image\n",
    "X = utils.make_image(feature_array)\n",
    "# image is a 4D tensor (n_samples, n_pixels_x, n_pixels_y, n_channels)\n",
    "X_train, y_train = keras_to_torch(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a16be8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load testing file\n",
    "feature_array_test, label_array_test, spec_array_test = utils.get_features_labels('root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/test/ntuple_merged_0.root', features, spectators, labels, remove_mass_pt_window=False, entry_stop=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accd1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make image\n",
    "X_test = utils.make_image(feature_array_test)\n",
    "X_test, y_test = keras_to_torch(X_test, label_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0ad7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check numbers in arguments\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        print(input_shape)\n",
    "        self.conv1 = nn.Conv2d(input_shape[0], 128, kernel_size=7, stride=2, padding=3)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.lrn1 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.lrn2 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Inception modules\n",
    "        self.inc1 = Inception_Module(64, 'inc1')\n",
    "        self.inc2 = Inception_Module(256, 'inc2')\n",
    "        \n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # More inception modules\n",
    "        self.inc3 = Inception_Module(256, 'inc3')\n",
    "        \n",
    "        self.pool4 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        #self.fc = nn.Linear(256, num_classes)  # Adjust the input size according to the output of the previous layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.lrn1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.lrn2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Inception modules\n",
    "        x = self.inc1(x)\n",
    "        x = self.inc2(x)\n",
    "\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # More inception modules\n",
    "        x = self.inc3(x)\n",
    "\n",
    "        x = self.pool4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37b1061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_Module(nn.Module):\n",
    "    def __init__(self, in_channels, name):\n",
    "        super(Inception_Module, self).__init__()\n",
    "        \n",
    "        self.conv_a1 = nn.Conv2d(in_channels, 64, kernel_size=1)\n",
    "        nn.init.kaiming_normal_(self.conv_a1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        self.conv_b1 = nn.Conv2d(in_channels, 96, kernel_size=1)\n",
    "        nn.init.kaiming_normal_(self.conv_b1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        self.conv_c1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.pool_d1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.conv_b2 = nn.Conv2d(96, 128, kernel_size=3, padding=1)\n",
    "        self.conv_c2 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
    "        self.conv_d2 = nn.Conv2d(in_channels, 32, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a1 = F.relu(self.conv_a1(x))\n",
    "        b1 = F.relu(self.conv_b1(x))\n",
    "        c1 = F.relu(self.conv_c1(x))\n",
    "        d1 = F.relu(self.pool_d1(x))\n",
    "        \n",
    "        b2 = F.relu(self.conv_b2(b1))\n",
    "        c2 = F.relu(self.conv_c2(c1))\n",
    "        d2 = F.relu(self.conv_d2(d1))\n",
    "\n",
    "        output = torch.cat((a1, b2, c2, d2), dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13104b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, test_loader, device):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "    def train(self, epochs, learning_rate):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.train_loader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                _, labels = torch.max(labels, dim=1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "            print(f'Epoch {epoch + 1}, Loss: {running_loss / (i + 1)}')\n",
    "\n",
    "    def test(self):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in self.test_loader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print('Accuracy: %d %%' % (100 * correct / total))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73d2e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39f93c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data(X_train, y_train)\n",
    "test_dataset = Data(X_train, y_train)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6746f66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "209e3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43f3e3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and trainer\n",
    "model = CNNModel(train_dataset[0][0].shape, num_classes=num_classes)\n",
    "trainer = Trainer(model, train_loader, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26c685e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.36356661655008793\n",
      "Epoch 2, Loss: 0.36272842064499855\n",
      "Epoch 3, Loss: 0.3631594283506274\n",
      "Epoch 4, Loss: 0.3817851319909096\n",
      "Epoch 5, Loss: 0.381181076169014\n",
      "Epoch 6, Loss: 0.3627150133252144\n",
      "Epoch 7, Loss: 0.3994704317301512\n",
      "Epoch 8, Loss: 0.4168376363813877\n",
      "Epoch 9, Loss: 0.3819835036993027\n",
      "Epoch 10, Loss: 0.39910103380680084\n",
      "Epoch 11, Loss: 0.3811473809182644\n",
      "Epoch 12, Loss: 0.38070685788989067\n",
      "Epoch 13, Loss: 0.3807355612516403\n",
      "Epoch 14, Loss: 0.38116296380758286\n",
      "Epoch 15, Loss: 0.3810058906674385\n",
      "Epoch 16, Loss: 0.43632010743021965\n",
      "Epoch 17, Loss: 0.4149100072681904\n",
      "Epoch 18, Loss: 0.36562617495656013\n",
      "Epoch 19, Loss: 0.4162025637924671\n",
      "Epoch 20, Loss: 0.41616610810160637\n",
      "Epoch 21, Loss: 0.43319283425807953\n",
      "Epoch 22, Loss: 0.3985750302672386\n",
      "Epoch 23, Loss: 0.40015049278736115\n",
      "Epoch 24, Loss: 0.3991139456629753\n",
      "Epoch 25, Loss: 0.39908481016755104\n"
     ]
    }
   ],
   "source": [
    "# Train and test the model\n",
    "trainer.train(epochs=25, learning_rate=0.001)\n",
    "#trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db8efdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
